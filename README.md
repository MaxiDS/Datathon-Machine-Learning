# <h1 align=center>**`Datathon - Machine Learning`**</h1>
# <h3 align=center> **Proyecto de clasificacion con ML** </h3>
<p align="center">
<img src="https://www.nephrocare.com.ar/fileadmin/user_upload/assets/images/master/professionals/Careers/NC_Team/NC_team_iStock-1045200338.png"  height=400>
</p>

<hr>

## **TABLA DE CONTENIDO**  
+ 1-Introducci√≥n.  
+ 2-Objetivo de trabajo.  
+ 3-Principales tecnolog√≠as utilizadas.  
+ 4-Plan de Acci√≥n. 
+ 5-Observaciones.   
+ 6-Conclusiones.  

<hr>  

## **1-Introducci√≥n**  

Hola! üëã mi nombre es Lucas Maximiliano Seidl y este repositorio contiene mi proyecto individual para el "Datathon - Machine Learning" de la carrera de Data Science en la academia Henry.  
En este trabajo cree un modelo que puede predecir, a partir de ciertos datos, si un paciente va a permanecer en el hospital durante m√°s o menos de 8 d√≠as.

<hr>

## **2-Objetivo de trabajo**  

Un importante Centro de Salud lo ha contratado con el fin de poder predecir si un paciente tendr√° una estancia hospitalaria prolongada o no. Para ello tenemos dos archivos csv, uno "train" con el cual vamos a entrenar nuestro modelo de ML y "test" en el cual vamos a aplicar el modelo realizado y conseguir las predicciones.  

+ An√°lisis exploratorio de los datos (EDA).

+ Divisi√≥n de dataset en train y test utilizando train_test_split, CV, KFold o similares.

+ Entrenamiento y predicci√≥n utilizando un Modelo de Machine Learning adecuado al problema (clasificaci√≥n o regresi√≥n).

+ Utilizaci√≥n de Pipelines en la producci√≥n del modelo.

+ Comentarios y redacci√≥n con la fundamentaci√≥n de la soluci√≥n propuesta, escrita en Markdown en el Jupyter Notebook (.ipynb) o bien en un documento aparte.

<hr>  

## **3-Principales tecnolog√≠as utilizadas**  
<p align="center">

<img src="https://anderfernandez.com/wp-content/uploads/2021/01/Como-programar-arbol-de-decision-en-Python.jpg"  height=400>
</p>

- Python üêç  
Es un lenguaje de programaci√≥n ampliamente utilizado en las aplicaciones web, el desarrollo de software, la ciencia de datos y el machine learning (ML).  
https://docs.python.org/3/  
  - Scikit-learn ü§ñ  
    Es una biblioteca de aprendizaje autom√°tico de software gratuito para el lenguaje de programaci√≥n Python. https://scikit-learn.org/stable/  
  - Pandas üêº 
  Es una librer√≠a de Python especializada en la manipulaci√≥n y el an√°lisis de datos. Ofrece estructuras de datos y operaciones para manipular tablas num√©ricas y series temporales, es como el Excel de Python. https://pandas.pydata.org/docs/  
  - Numpy üßÆ  
  NumPy es una biblioteca para el lenguaje de programaci√≥n Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colecci√≥n de funciones matem√°ticas de alto nivel para operar con ellas. https://numpy.org/doc/  
  - Matplotlib üìà   
  Es una biblioteca para la generaci√≥n de gr√°ficos en dos dimensiones, a partir de datos contenidos en listas o arrays en el lenguaje de programaci√≥n Python.
  https://matplotlib.org/stable/index.html  
  - Seaborn üìä  
  Es una librer√≠a de visualizaci√≥n de datos para Python desarrollada sobre matplotlib . https://seaborn.pydata.org/  
  - Scipy üî¨  
  Es una biblioteca libre y de c√≥digo abierto para Python. Se compone de herramientas y algoritmos matem√°ticos. https://docs.scipy.org/doc/scipy/  
  - Pipeline ‚ôª  
  La clase Pipeline de Scikit-learn est√° dise√±ada como una forma manejable de aplicar una serie de transformaciones de datos seguidas por la aplicaci√≥n de un estimador 
  https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html  
  
  <hr>  
  
  ## **4-Plan de Acci√≥n** 
  
  
<p align="center">
<img src="https://cdn.discordapp.com/attachments/1027950645577261117/1051530466097893427/image.png"  height=200>
</p>
  
   
 Un breve resumen de lo que se comenta en el notebook es que se llev√≥ a cabo un an√°lisis exploratorio de los datos (EDA), en el que se verificaron los valores nulos y duplicados, y se control√≥ la correlaci√≥n entre las variables mediante la prueba chi2_contingency. Luego, se normalizaron los datos utilizando OneHotEncoder y LabelEncoder.  
 
 Se entrenaron los modelos X e Y, obteniendo mejores resultados con un random_state=32. Se utiliz√≥ un Pipeline para comparar el rendimiento de decisiontreeclassifier y regresi√≥n log√≠stica, y se seleccion√≥ decisiontreeclassifier como el mejor modelo.  
 
 Posteriormente, se utiliz√≥ grid search para ajustar los par√°metros del modelo y mejorar su rendimiento una vez en producci√≥n. Finalmente, se implement√≥ el modelo entrenado para predecir el conjunto de datos "csv test" y se gener√≥ un archivo csv con los resultados, que se subi√≥ con el nombre "MaxiDS".  
 
  <hr>  
  
   ## **5-Observaciones**  
   
   Se aplic√≥ LabelEncoder en lugar de OneHotEncoder a las columnas "Age" y "Severity of Illness" porque esto mejor√≥ la precisi√≥n del modelo. Se decidi√≥ no eliminar la columna "Admission_Deposit" despu√©s de realizar pruebas ya que esto tambi√©n mejor√≥ el rendimiento del modelo.  
   
   Cuando se definen X_train e Y_train, se obtienen mejores resultados con un random_state=32. El uso de grid search nos permiti√≥ encontrar los siguientes par√°metros √≥ptimos para mejorar nuestro √°rbol de decisi√≥n: 'criterion': 'gini', 'max_depth': 19, 'random_state': 32, 'splitter': 'best'.  
   
   Finalmente, nuestro modelo en producci√≥n tuvo un rendimiento de Recall del 81,16% y Accuracy del 77,07% cuando se utiliz√≥ "csv test" como conjunto de datos de prueba.  
   
   <hr>
   
   ## **6-Conclusiones**  
   
   Este trabajo me permiti√≥ ampliar mis conocimientos en programaci√≥n y en el uso de librer√≠as de machine learning como Sklearn y Scipy. Aprend√≠ a mejorar el rendimiento de un modelo utilizando grid search y a profundizar en el uso de √°rboles de decisi√≥n. Me siento muy satisfecho de haber cumplido con los objetivos propuestos y de haber ampliado mis conocimientos en esta √°rea.  
   <hr>
   
<p align="center">
<img src="https://miro.medium.com/max/1120/1*oZjtmox-nEmcnW1NV5GVbw.gif"  height=200>
</p>
   
   ¬°Muchas gracias por leer mi trabajo!üòÅ Me alegra haber sido de tu inter√©s.  
   Te comparto mi linkedin para que podamos conectarnos y seguir en contacto: https://www.linkedin.com/in/maxi-seidl/  
   ¬°Hasta pronto!üëã
   
